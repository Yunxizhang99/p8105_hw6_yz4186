---
title: "p8105_hw6_yz4186"
author: "Yunxi Zhang"
date: "12/4/2021"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(p8105.datasets)
library(modelr)
library(mgcv)
library(rvest)
knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)
theme_set(theme_minimal() + theme(legend.position = "bottom"))
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```


## Problem 1

#### Load and clean the data for regression analysis (i.e. convert numeric to factor where appropriate, check for missing data, etc.).

```{r}
## check for missing data
anyNA(read_csv("./birthweight.csv"))

## convert numeric to factor
birthweight_df = 
  read_csv("./birthweight.csv") %>% 
 mutate(
    babysex = as.factor(babysex),
    frace = as.factor(frace),
    malform = as.factor(malform),
    mrace = as.factor(mrace)
  ) 
```


construct the two models.

```{r}
lm_mod1 = lm(bwt ~ blength + gaweeks, data = birthweight_df)
broom::tidy(lm_mod1)

lm_mod2 = lm(bwt ~ bhead + blength + babysex + bhead*blength + blength*babysex + bhead*babysex + bhead*blength*babysex, data = birthweight_df)
broom::tidy(lm_mod2)
```

propose the regression model for birthweight using all predictors.
And then check AIC.

```{r }
mod_all = lm(bwt ~ .,data = birthweight_df)
broom::tidy(mod_all) 

step(mod_all, direction = 'backward') %>% broom::tidy() 
```

According to the result, we can find some reasonable predictors.

```{r }
mod_fit = lm(bwt ~ fincome + frace + parity + mrace + babysex + mheight+ ppwt+ gaweeks + smoken + wtgain + blength + bhead, data = birthweight_df)
broom::tidy(mod_fit)
```

make a plot.

```{r }
birthweight_df %>% 
  add_predictions(mod_fit) %>% 
  add_residuals(mod_fit) %>% 
  ggplot(aes( x = pred, y = resid)) +
  geom_point(alpha = 0.5)
```

From the plot I found that all the points are centered at 0 which makes sense. 
And most points are scatter around the prediction. However, some points are departure towards left in prediction and some are departure 


##### Model comparison

Cross validation.

```{r }
cv_df = crossv_mc(birthweight_df, 100)

cv_df = 
  cv_df %>% 
  mutate(
    mod1 = map(.x = train, ~lm(bwt ~ blength + gaweeks, data = birthweight_df)),
    mod2 = map(.x = train, ~lm(bwt ~ bhead + blength + babysex + bhead*blength + blength*babysex + bhead*babysex + bhead*blength*babysex, data = birthweight_df)),
    mod_fit = map(.x = train, ~lm(bwt ~ fincome + frace + parity + mrace + babysex + mheight+ ppwt+ gaweeks + smoken + wtgain + blength + bhead, data = birthweight_df))
  ) %>% 
  mutate(
    rmse_mod1 = map2_dbl(.x = mod1, .y = test, ~rmse(model = .x, data =.y)),
    rmse_mod2 = map2_dbl(.x = mod2, .y = test, ~rmse(model = .x, data =.y)),
    rmse_fit = map2_dbl(.x = mod_fit, .y = test, ~rmse(model = .x, data =.y))
  )
```

Compute RMSE.

```{r }
cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model",
    values_to = "rmse",
    names_prefix = "rmse_"
  ) %>% 
  ggplot(aes(x = model, y = rmse, color = model)) + geom_violin() +
  labs(
    x = "Model",
    y = "RMSE",
    title = "RMSEs of 3 models"
  )
```
From the plot, I found that the fitted model has the smallest RMSE which indicates that it is the best model among the three models.


## Problem 2

```{r }
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```

Do the bootstrap.

```{r}
weather_boot =
  weather_df %>% 
  drop_na() %>% 
  bootstrap(5000, id = "strap_number") %>% 
  mutate(
    models = map(.x = strap, ~lm(tmax ~ tmin, data = .x)),
    results = map(models, broom::tidy),
    result_r = map(models, broom::glance)
  ) %>% 
  select(strap_number, results, result_r) %>% 
  unnest(results, result_r)

weather_boot
```

Calculate $log(\beta_{0} * \beta_{1})$

```{r}
log_df =
  weather_boot %>% 
  dplyr::select(strap_number, term, estimate) %>% 
  pivot_wider(names_from = term,
              values_from = estimate) %>% 
  rename(intercept ="(Intercept)") %>% 
  mutate(log_value = log10(intercept*tmin))

log_df
```

Plot the distribution of $log(\beta_{0} * \beta_{1})$

```{r}
log_df %>% 
  ggplot(aes(x = log_value)) +
  geom_density() + 
  xlab("log(beta0 * beta1)") +
  ggtitle("Distribution of log(beta0 * beta1)")
```

From the plot I found that the distribution of $log(\beta_{0} * \beta_{1})$ is approximately normal. And when it closes to 0.875, it has the largest density.

Calculate the 95% CI.

```{r}
log_df %>% 
  summarize(
    ci_lower = quantile(log_value, 0.025),
    ci_upper = quantile(log_value, 0.975)
  ) %>% 
  knitr::kable()
```


Calculate $r^2$.

```{r}
r_square =
  weather_boot %>% 
  filter(term == "tmin") %>% 
  dplyr::select(r.squared) 

r_square
```

Plot the distribution of  $r^2$.

```{r}
r_square %>% 
  ggplot(aes(x = r.squared)) +
  geom_density() + 
  xlab("r_square") +
  ggtitle("Distribution of r_square")
```

From the plot, I found that the distribution of  $r^2$ is approximately normal, and when it get close to 0.912, it has the largest density. 

Calculate the 95% CI. 

```{r}
r_square %>% 
  summarize(
    ci_lower = quantile(r.squared, 0.025),
    ci_upper = quantile(r.squared,0.975)
  ) %>% 
  knitr::kable()
```












